{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobzhao/anaconda3/envs/prophet/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Importing plotly failed. Interactive plots will not work.\n",
      "2024-06-15 17:13:35.602834: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import darts\n",
    "from darts import TimeSeries\n",
    "from darts.models import NaiveSeasonal, NaiveMean, NaiveDrift\n",
    "from darts.models import StatsForecastAutoARIMA, StatsForecastAutoETS, StatsForecastAutoCES, RNNModel, ExponentialSmoothing, BlockRNNModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from darts.models import RNNModel, ExponentialSmoothing, BlockRNNModel\n",
    "from darts.metrics import mape, mase, mse, rmse, ase, ape, r2_score, smape\n",
    "from darts.utils.statistics import check_seasonality, plot_acf\n",
    "from darts.datasets import AirPassengersDataset, SunspotsDataset\n",
    "from darts.utils.timeseries_generation import datetime_attribute_timeseries\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dropout, Dense, Flatten\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "logging.disable(logging.CRITICAL)\n",
    "import random\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD, Nadam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, mean_absolute_error\n",
    "from tensorflow.keras.losses import Huber\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "import os\n",
    "K.clear_session()\n",
    "tf.keras.backend.clear_session()\n",
    "from hyperopt import base\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "os.environ['HYPEROPT_FMIN_SEED'] = \"1\"\n",
    "random.seed(88)\n",
    "np.random.seed(88)\n",
    "tf.random.set_seed(88)\n",
    "base.have_been_bugged = False  \n",
    "rstate = np.random.default_rng(88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = pd.read_csv('time_series_thesis_question_1.csv', index_col=0)\n",
    "df_total.index = pd.to_datetime(df_total.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = TimeSeries.from_dataframe(df_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1, val_1 = df.split_before(pd.Timestamp('20230101'))\n",
    "train_2, val_2 = df.split_before(pd.Timestamp('20230401'))\n",
    "train_3, val_3 = df.split_before(pd.Timestamp('20230701'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Xy(sliding_windows):\n",
    "    X = [[list(window[:-1]) for window in windows] for windows in sliding_windows]\n",
    "    y = [[window[-1] for window in windows] for windows in sliding_windows]\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error, mean_absolute_error\n",
    "\n",
    "def spliter(df_total,\n",
    "            k = 4,\n",
    "            test_size = 3,\n",
    "            val_size = 3):\n",
    "    test = []\n",
    "    val = []\n",
    "    train = []\n",
    "    NN_sets = {}\n",
    "    window_size = k+1\n",
    "\n",
    "\n",
    "    for col in df_total.columns:\n",
    "        windows = [np.array(window) for window in df_total[col].rolling(window_size) if len(window) == window_size]\n",
    "        test.append(windows[-(test_size):])\n",
    "        val.append(windows[-(test_size+val_size):-(test_size)])\n",
    "        train.append(windows[:-(test_size+val_size)])\n",
    "    NN_sets['X_train'], NN_sets['y_train'] = Xy(train)\n",
    "    NN_sets['X_val'], NN_sets['y_val'] = Xy(val)\n",
    "    NN_sets['X_test'], NN_sets['y_test'] = Xy(test)\n",
    "    return NN_sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import darts\n",
    "def NN_metricker(y_pred):\n",
    "  y_pred_df = pd.DataFrame(y_pred.reshape((-1, 3)).transpose())\n",
    "  y_pred_df.columns = df_total.columns\n",
    "  y_pred_df.index = df_total.index[-3:]\n",
    "  y_pred_tf = TimeSeries.from_dataframe(y_pred_df)\n",
    "  SMAPE = darts.metrics.smape(val_1, y_pred_tf)\n",
    "  MASE = darts.metrics.mase(val_1, y_pred_tf, train_1)\n",
    "  MAE = darts.metrics.mae(val_1, y_pred_tf)\n",
    "  print(\n",
    "      \"Symmetric Mean absolute percentage error: {:.2f}%.\".format(\n",
    "          SMAPE),\n",
    "          \"MASE: {:.2f}\".format(MASE),\n",
    "          \"MAE: {:.2f}\".format(MAE)\n",
    "      )\n",
    "  return y_pred_df, SMAPE, MASE, MAE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ1 Results from CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_2cnn_model(window, n_layers, n_nodes, optimizer_name, lr, kernel_size, df=df_total):\n",
    "    NN_sets = spliter(df, k=window)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=n_nodes, kernel_size= kernel_size, activation='relu', input_shape=(window, 1)))\n",
    "    model.add(Conv1D(filters=n_nodes/2, kernel_size=kernel_size, activation='relu', input_shape=(window, 1)))\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    for _ in range(n_layers):\n",
    "        model.add(Dense(n_nodes/2, activation='relu'))\n",
    "        \n",
    "    model.add(Dense(1))\n",
    "\n",
    "    optimizer_class = {'adam': Adam, 'rmsprop': RMSprop, 'sgd': SGD, 'nadam': Nadam}[optimizer_name]\n",
    "    optimizer = optimizer_class(lr)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=Huber())\n",
    "\n",
    "    return model, NN_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [24:59<00:00, 14.99s/trial, best loss: 0.8905212879180908]\n",
      "Best hyperparameters:\n",
      "{'kernel_size': 0, 'lr': 4, 'n_layers': 1, 'n_nodes': 1, 'optimizer': 2, 'window': 1}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD, Nadam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, mean_absolute_error\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "K.clear_session()\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Hyperparameters to tune\n",
    "window_values = [16, 20, 24, 28]\n",
    "hidden_layers_values = [1, 2, 3]\n",
    "hidden_nodes_values = [8, 16, 32, 64]\n",
    "optimizer_values = ['adam', 'rmsprop', 'nadam']\n",
    "kernel_size_values = [3, 5, 7, 9, 12]\n",
    "lr_values = list(np.arange(1e-4, 11e-4, 1e-4))\n",
    "\n",
    "trials_results = []\n",
    "def is_compatible(window, kernel_size):\n",
    "    if window == 16 and kernel_size >= 9:\n",
    "        return False\n",
    "    elif window == 20 and kernel_size >= 12:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def objective(params):\n",
    "    window = int(params['window'])\n",
    "    n_layers = int(params['n_layers'])\n",
    "    n_nodes = int(params['n_nodes'])\n",
    "    optimizer_name = params['optimizer']\n",
    "    lr = params['lr']\n",
    "    kernel_size = int(params['kernel_size'])\n",
    "\n",
    "    if not is_compatible(window, kernel_size):\n",
    "        return {'status': STATUS_OK, 'loss': np.inf}\n",
    "\n",
    "\n",
    "    model, NN_sets = create_2cnn_model(window, n_layers, n_nodes, optimizer_name, lr, kernel_size)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    history = model.fit(\n",
    "        NN_sets['X_train'].reshape((-1, NN_sets['X_train'].shape[-1])),\n",
    "        NN_sets['y_train'].reshape((-1, 1)),\n",
    "        epochs=30,\n",
    "        batch_size=16,\n",
    "        validation_data=(NN_sets['X_val'].reshape((-1, NN_sets['X_val'].shape[-1])),\n",
    "                         NN_sets['y_val'].reshape((-1, 1))),\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=0\n",
    "    )\n",
    "    val_loss = history.history['val_loss'][-1]\n",
    "    trials_results.append({'params': params, 'val_loss': val_loss})\n",
    "\n",
    "    return {'loss': val_loss, 'status': STATUS_OK}\n",
    "\n",
    "# Define the hyperparameter search space\n",
    "search_space = {\n",
    "    'window': hp.choice('window', window_values),\n",
    "    'n_layers': hp.choice('n_layers', hidden_layers_values),\n",
    "    'n_nodes': hp.choice('n_nodes', hidden_nodes_values),\n",
    "    'optimizer': hp.choice('optimizer', optimizer_values),\n",
    "    'lr': hp.choice('lr', lr_values),\n",
    "    'kernel_size': hp.choice('kernel_size', kernel_size_values)  \n",
    "}\n",
    "# Conduct the Bayesian optimization\n",
    "trials = Trials()\n",
    "best = fmin(objective, search_space, algo=tpe.suggest, max_evals=100, trials=trials, rstate=rstate)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding validation loss\n",
    "print('Best hyperparameters:')\n",
    "print(best)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Window: 20\n",
      "Best Number of Layers: 2\n",
      "Best Number of Nodes: 16\n",
      "Best Optimizer Name: nadam\n",
      "Best Learning Rate: 0.0005\n",
      "Best Kernel Size: 3\n",
      "Epoch 1/30\n",
      "628/628 [==============================] - 4s 3ms/step - loss: 1.8693 - val_loss: 1.3749\n",
      "Epoch 2/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.9318 - val_loss: 1.1227\n",
      "Epoch 3/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7911 - val_loss: 1.0306\n",
      "Epoch 4/30\n",
      "628/628 [==============================] - 2s 2ms/step - loss: 0.7446 - val_loss: 0.9630\n",
      "Epoch 5/30\n",
      "628/628 [==============================] - 2s 2ms/step - loss: 0.7255 - val_loss: 0.9275\n",
      "Epoch 6/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 0.7199 - val_loss: 0.9523\n",
      "Epoch 7/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7177 - val_loss: 0.9108\n",
      "Epoch 8/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7153 - val_loss: 0.9096\n",
      "Epoch 9/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 0.7144 - val_loss: 0.9565\n",
      "Epoch 10/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 0.7157 - val_loss: 0.9168\n",
      "Epoch 11/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7127 - val_loss: 0.9171\n",
      "Epoch 12/30\n",
      "628/628 [==============================] - 2s 2ms/step - loss: 0.7141 - val_loss: 0.9045\n",
      "Epoch 13/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7127 - val_loss: 0.9040\n",
      "Epoch 14/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7125 - val_loss: 0.9050\n",
      "Epoch 15/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 0.7123 - val_loss: 0.9125\n",
      "Epoch 16/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7100 - val_loss: 0.9078\n",
      "Epoch 17/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7116 - val_loss: 0.9162\n",
      "Epoch 18/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7087 - val_loss: 0.9044\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "tf.keras.backend.clear_session()\n",
    "# Map the indices back to the actual values\n",
    "best_window = window_values[best['window']]\n",
    "best_n_layers = hidden_layers_values[best['n_layers']]\n",
    "best_n_nodes = hidden_nodes_values[best['n_nodes']]\n",
    "best_optimizer_name = optimizer_values[best['optimizer']]\n",
    "best_lr = lr_values[best['lr']]\n",
    "best_kernel_size = kernel_size_values[best['kernel_size']]\n",
    "\n",
    "print(f\"Best Window: {best_window}\")\n",
    "print(f\"Best Number of Layers: {best_n_layers}\")\n",
    "print(f\"Best Number of Nodes: {best_n_nodes}\")\n",
    "print(f\"Best Optimizer Name: {best_optimizer_name}\")\n",
    "print(f\"Best Learning Rate: {best_lr}\")\n",
    "print(f\"Best Kernel Size: {best_kernel_size}\")\n",
    "best_model, NN_sets = create_2cnn_model(best_window, best_n_layers, best_n_nodes, best_optimizer_name, best_lr, best_kernel_size)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "history = best_model.fit(NN_sets['X_train'].reshape((-1, best_window)),\n",
    "                         NN_sets['y_train'].reshape((-1, 1)),\n",
    "                         epochs=30,\n",
    "                         batch_size=16,\n",
    "                         validation_data=(NN_sets['X_val'].reshape((-1, best_window)),\n",
    "                                          NN_sets['y_val'].reshape((-1, 1))),\n",
    "                         callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 0s 2ms/step\n",
      "Symmetric Mean absolute percentage error: 14.73%. MASE: 1.12 MAE: 1.16\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model.predict(NN_sets['X_test'].reshape((-1, best_window, 1)))\n",
    "y_pred_df = NN_metricker(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_loss</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>lr</th>\n",
       "      <th>n_layers</th>\n",
       "      <th>n_nodes</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>window</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.953209</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>adam</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.013165</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.925028</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.910332</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>adam</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.044035</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>adam</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   val_loss  kernel_size      lr  n_layers  n_nodes optimizer  window\n",
       "0  0.953209            3  0.0010         2       16      adam      28\n",
       "1  1.013165            3  0.0003         3       16   rmsprop      20\n",
       "2  0.925028            7  0.0009         2        8   rmsprop      24\n",
       "3  0.910332            3  0.0001         2       32      adam      20\n",
       "4  1.044035            7  0.0009         3       64      adam      28"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming trials_results is your list of dictionaries\n",
    "df = pd.DataFrame(trials_results)\n",
    "\n",
    "# If you want to flatten the 'params' column into separate columns\n",
    "df = pd.concat([df.drop(['params'], axis=1), df['params'].apply(pd.Series)], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "if not os.path.exists('final_thesis_CNN'):\n",
    "    os.makedirs('final_thesis_CNN')\n",
    "\n",
    "# Write df to a csv file in the specified directory\n",
    "df.to_csv('final_thesis_CNN/CNN_tuning_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = {'kernel_size': 0, 'lr': 4, 'n_layers': 1, 'n_nodes': 1, 'optimizer': 2, 'window': 1}\n",
    "# Hyperparameters to tune\n",
    "window_values = [16, 20, 24, 28]\n",
    "hidden_layers_values = [1, 2, 3]\n",
    "hidden_nodes_values = [8, 16, 32, 64]\n",
    "optimizer_values = ['adam', 'rmsprop', 'nadam']\n",
    "kernel_size_values = [3, 5, 7, 9, 12]\n",
    "lr_values = list(np.arange(1e-4, 11e-4, 1e-4))\n",
    "\n",
    "best_window = window_values[best['window']]\n",
    "best_n_layers = hidden_layers_values[best['n_layers']]\n",
    "best_n_nodes = hidden_nodes_values[best['n_nodes']]\n",
    "best_optimizer_name = optimizer_values[best['optimizer']]\n",
    "best_lr = lr_values[best['lr']]\n",
    "best_kernel_size = kernel_size_values[best['kernel_size']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "628/628 [==============================] - 2s 3ms/step - loss: 0.7128 - val_loss: 0.8939\n",
      "Epoch 9/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 0.7121 - val_loss: 0.9501\n",
      "Epoch 10/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 0.7115 - val_loss: 0.8986\n",
      "Epoch 11/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 0.7091 - val_loss: 0.9148\n",
      "Epoch 12/30\n",
      "628/628 [==============================] - 2s 4ms/step - loss: 0.7097 - val_loss: 0.9128\n",
      "Epoch 13/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 0.7087 - val_loss: 0.8900\n",
      "Epoch 14/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 0.7072 - val_loss: 0.8879\n",
      "Epoch 15/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 0.7062 - val_loss: 0.8867\n",
      "Epoch 16/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 0.7043 - val_loss: 0.8927\n",
      "Epoch 17/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 0.7055 - val_loss: 0.8974\n",
      "Epoch 18/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 0.7026 - val_loss: 0.8938\n",
      "Epoch 19/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 0.7039 - val_loss: 0.8867\n",
      "Epoch 20/30\n",
      "628/628 [==============================] - 2s 2ms/step - loss: 0.7018 - val_loss: 0.8895\n",
      "Epoch 21/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 0.7021 - val_loss: 0.9701\n",
      "Epoch 22/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 0.7031 - val_loss: 0.9470\n",
      "Epoch 23/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 0.6987 - val_loss: 0.9272\n",
      "Epoch 24/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 0.7004 - val_loss: 0.9195\n",
      "73/73 [==============================] - 0s 1ms/step\n",
      "Symmetric Mean absolute percentage error: 14.89%. MASE: 1.17 MAE: 1.16\n",
      "Epoch 1/30\n",
      "628/628 [==============================] - 4s 3ms/step - loss: 6.9750 - val_loss: 6.2047\n",
      "Epoch 2/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 5.6532 - val_loss: 4.6645\n",
      "Epoch 3/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 4.1245 - val_loss: 3.7103\n",
      "Epoch 4/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 3.4189 - val_loss: 3.5716\n",
      "Epoch 5/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 3.2758 - val_loss: 3.6015\n",
      "Epoch 6/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 3.2584 - val_loss: 3.6224\n",
      "Epoch 7/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 3.2568 - val_loss: 3.6302\n",
      "Epoch 8/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 3.2569 - val_loss: 3.6308\n",
      "Epoch 9/30\n",
      "628/628 [==============================] - 2s 4ms/step - loss: 3.2568 - val_loss: 3.6280\n",
      "73/73 [==============================] - 0s 1ms/step\n",
      "Symmetric Mean absolute percentage error: 47.99%. MASE: 5.19 MAE: 3.87\n",
      "Epoch 1/30\n",
      "628/628 [==============================] - 4s 3ms/step - loss: 1.3870 - val_loss: 1.2147\n",
      "Epoch 2/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.8142 - val_loss: 1.0071\n",
      "Epoch 3/30\n",
      "628/628 [==============================] - 2s 2ms/step - loss: 0.7482 - val_loss: 1.0402\n",
      "Epoch 4/30\n",
      "628/628 [==============================] - 2s 2ms/step - loss: 0.7352 - val_loss: 0.9434\n",
      "Epoch 5/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 0.7252 - val_loss: 0.9251\n",
      "Epoch 6/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 0.7232 - val_loss: 0.9300\n",
      "Epoch 7/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 0.7202 - val_loss: 0.9160\n",
      "Epoch 8/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7177 - val_loss: 0.9136\n",
      "Epoch 9/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 0.7167 - val_loss: 0.9399\n",
      "Epoch 10/30\n",
      "628/628 [==============================] - 2s 2ms/step - loss: 0.7156 - val_loss: 0.9129\n",
      "Epoch 11/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 0.7134 - val_loss: 0.9131\n",
      "Epoch 12/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 0.7137 - val_loss: 0.9034\n",
      "Epoch 13/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 0.7122 - val_loss: 0.9040\n",
      "Epoch 14/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 0.7112 - val_loss: 0.8950\n",
      "Epoch 15/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7092 - val_loss: 0.9054\n",
      "Epoch 16/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 0.7062 - val_loss: 0.9049\n",
      "Epoch 17/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 0.7074 - val_loss: 0.9082\n",
      "Epoch 18/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 0.7045 - val_loss: 0.9026\n",
      "Epoch 19/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 0.7059 - val_loss: 0.8921\n",
      "Epoch 20/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 0.7036 - val_loss: 0.9133\n",
      "Epoch 21/30\n",
      "628/628 [==============================] - 2s 4ms/step - loss: 0.7052 - val_loss: 0.9536\n",
      "Epoch 22/30\n",
      "628/628 [==============================] - 2s 2ms/step - loss: 0.7043 - val_loss: 0.9621\n",
      "Epoch 23/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7017 - val_loss: 0.9287\n",
      "Epoch 24/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7036 - val_loss: 0.9220\n",
      "73/73 [==============================] - 0s 1ms/step\n",
      "Symmetric Mean absolute percentage error: 15.26%. MASE: 1.20 MAE: 1.18\n",
      "Epoch 1/30\n",
      "628/628 [==============================] - 4s 2ms/step - loss: 1.8854 - val_loss: 1.5033\n",
      "Epoch 2/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 1.0180 - val_loss: 1.1613\n",
      "Epoch 3/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.8088 - val_loss: 1.0374\n",
      "Epoch 4/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 0.7483 - val_loss: 0.9527\n",
      "Epoch 5/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 0.7250 - val_loss: 0.9126\n",
      "Epoch 6/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 0.7193 - val_loss: 0.9113\n",
      "Epoch 7/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7159 - val_loss: 0.8999\n",
      "Epoch 8/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7137 - val_loss: 0.9036\n",
      "Epoch 9/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7134 - val_loss: 0.9390\n",
      "Epoch 10/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7132 - val_loss: 0.9079\n",
      "Epoch 11/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7111 - val_loss: 0.9107\n",
      "Epoch 12/30\n",
      "628/628 [==============================] - 2s 4ms/step - loss: 0.7117 - val_loss: 0.9005\n",
      "73/73 [==============================] - 0s 1ms/step\n",
      "Symmetric Mean absolute percentage error: 14.63%. MASE: 1.11 MAE: 1.16\n",
      "Epoch 1/30\n",
      "628/628 [==============================] - 4s 3ms/step - loss: 3.0462 - val_loss: 1.3372\n",
      "Epoch 2/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 0.9659 - val_loss: 1.1154\n",
      "Epoch 3/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.8111 - val_loss: 1.0622\n",
      "Epoch 4/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7532 - val_loss: 0.9548\n",
      "Epoch 5/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7294 - val_loss: 0.9201\n",
      "Epoch 6/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7227 - val_loss: 0.9121\n",
      "Epoch 7/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7181 - val_loss: 0.8968\n",
      "Epoch 8/30\n",
      "628/628 [==============================] - 2s 2ms/step - loss: 0.7155 - val_loss: 0.8922\n",
      "Epoch 9/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7151 - val_loss: 0.9195\n",
      "Epoch 10/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 0.7157 - val_loss: 0.8984\n",
      "Epoch 11/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7134 - val_loss: 0.8929\n",
      "Epoch 12/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7146 - val_loss: 0.8883\n",
      "Epoch 13/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7140 - val_loss: 0.8837\n",
      "Epoch 14/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7132 - val_loss: 0.8941\n",
      "Epoch 15/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7130 - val_loss: 0.8891\n",
      "Epoch 16/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7111 - val_loss: 0.8945\n",
      "Epoch 17/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7131 - val_loss: 0.8938\n",
      "Epoch 18/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7104 - val_loss: 0.8873\n",
      "73/73 [==============================] - 0s 968us/step\n",
      "Symmetric Mean absolute percentage error: 14.61%. MASE: 1.11 MAE: 1.14\n",
      "Epoch 1/30\n",
      "628/628 [==============================] - 3s 2ms/step - loss: 1.6619 - val_loss: 1.2797\n",
      "Epoch 2/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.9078 - val_loss: 1.0689\n",
      "Epoch 3/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7995 - val_loss: 1.0495\n",
      "Epoch 4/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7639 - val_loss: 0.9739\n",
      "Epoch 5/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7417 - val_loss: 0.9377\n",
      "Epoch 6/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7293 - val_loss: 0.9296\n",
      "Epoch 7/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7207 - val_loss: 0.9083\n",
      "Epoch 8/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7149 - val_loss: 0.9051\n",
      "Epoch 9/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7150 - val_loss: 0.9395\n",
      "Epoch 10/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7144 - val_loss: 0.9090\n",
      "Epoch 11/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7127 - val_loss: 0.9037\n",
      "Epoch 12/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7132 - val_loss: 0.8946\n",
      "Epoch 13/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7131 - val_loss: 0.8891\n",
      "Epoch 14/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7121 - val_loss: 0.8925\n",
      "Epoch 15/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7103 - val_loss: 0.8961\n",
      "Epoch 16/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7090 - val_loss: 0.8978\n",
      "Epoch 17/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7112 - val_loss: 0.9027\n",
      "Epoch 18/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7088 - val_loss: 0.8940\n",
      "73/73 [==============================] - 0s 910us/step\n",
      "Symmetric Mean absolute percentage error: 14.43%. MASE: 1.10 MAE: 1.13\n",
      "Epoch 1/30\n",
      "628/628 [==============================] - 3s 2ms/step - loss: 1.2573 - val_loss: 1.2095\n",
      "Epoch 2/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.8824 - val_loss: 1.0623\n",
      "Epoch 3/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7868 - val_loss: 1.0361\n",
      "Epoch 4/30\n",
      "628/628 [==============================] - 2s 2ms/step - loss: 0.7463 - val_loss: 0.9490\n",
      "Epoch 5/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7247 - val_loss: 0.9209\n",
      "Epoch 6/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7201 - val_loss: 0.9256\n",
      "Epoch 7/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7189 - val_loss: 0.9060\n",
      "Epoch 8/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7161 - val_loss: 0.9064\n",
      "Epoch 9/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7153 - val_loss: 0.9221\n",
      "Epoch 10/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7147 - val_loss: 0.9136\n",
      "Epoch 11/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7130 - val_loss: 0.9088\n",
      "Epoch 12/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7144 - val_loss: 0.9003\n",
      "Epoch 13/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7134 - val_loss: 0.8980\n",
      "Epoch 14/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7120 - val_loss: 0.9024\n",
      "Epoch 15/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7106 - val_loss: 0.9053\n",
      "Epoch 16/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7080 - val_loss: 0.9114\n",
      "Epoch 17/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7101 - val_loss: 0.9114\n",
      "Epoch 18/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7065 - val_loss: 0.9055\n",
      "73/73 [==============================] - 0s 1000us/step\n",
      "Symmetric Mean absolute percentage error: 14.47%. MASE: 1.12 MAE: 1.13\n",
      "Epoch 1/30\n",
      "628/628 [==============================] - 4s 2ms/step - loss: 1.6986 - val_loss: 1.3543\n",
      "Epoch 2/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.9453 - val_loss: 1.0531\n",
      "Epoch 3/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7687 - val_loss: 1.0536\n",
      "Epoch 4/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 0.7328 - val_loss: 0.9425\n",
      "Epoch 5/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7196 - val_loss: 0.9241\n",
      "Epoch 6/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7188 - val_loss: 0.9306\n",
      "Epoch 7/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7184 - val_loss: 0.9089\n",
      "Epoch 8/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7163 - val_loss: 0.9099\n",
      "Epoch 9/30\n",
      "628/628 [==============================] - 2s 2ms/step - loss: 0.7163 - val_loss: 0.9247\n",
      "Epoch 10/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 0.7163 - val_loss: 0.9136\n",
      "Epoch 11/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7148 - val_loss: 0.9085\n",
      "Epoch 12/30\n",
      "628/628 [==============================] - 2s 2ms/step - loss: 0.7154 - val_loss: 0.9086\n",
      "Epoch 13/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7152 - val_loss: 0.9086\n",
      "Epoch 14/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 0.7143 - val_loss: 0.9106\n",
      "Epoch 15/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 0.7132 - val_loss: 0.9138\n",
      "Epoch 16/30\n",
      "628/628 [==============================] - 2s 2ms/step - loss: 0.7124 - val_loss: 0.9195\n",
      "73/73 [==============================] - 0s 955us/step\n",
      "Symmetric Mean absolute percentage error: 14.94%. MASE: 1.15 MAE: 1.15\n",
      "Epoch 1/30\n",
      "628/628 [==============================] - 4s 2ms/step - loss: 1.3025 - val_loss: 1.2283\n",
      "Epoch 2/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.8702 - val_loss: 1.0192\n",
      "Epoch 3/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7753 - val_loss: 1.0129\n",
      "Epoch 4/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7461 - val_loss: 0.9408\n",
      "Epoch 5/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7280 - val_loss: 0.9104\n",
      "Epoch 6/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7208 - val_loss: 0.9202\n",
      "Epoch 7/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7197 - val_loss: 0.9000\n",
      "Epoch 8/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7161 - val_loss: 0.9016\n",
      "Epoch 9/30\n",
      "628/628 [==============================] - 2s 2ms/step - loss: 0.7153 - val_loss: 0.9152\n",
      "Epoch 10/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7153 - val_loss: 0.9094\n",
      "Epoch 11/30\n",
      "628/628 [==============================] - 2s 2ms/step - loss: 0.7135 - val_loss: 0.8983\n",
      "Epoch 12/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7146 - val_loss: 0.8920\n",
      "Epoch 13/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 0.7142 - val_loss: 0.8955\n",
      "Epoch 14/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7118 - val_loss: 0.8903\n",
      "Epoch 15/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7122 - val_loss: 0.8957\n",
      "Epoch 16/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7107 - val_loss: 0.8973\n",
      "Epoch 17/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7117 - val_loss: 0.9012\n",
      "Epoch 18/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7087 - val_loss: 0.8947\n",
      "Epoch 19/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7101 - val_loss: 0.9037\n",
      "73/73 [==============================] - 0s 2ms/step\n",
      "Symmetric Mean absolute percentage error: 14.73%. MASE: 1.12 MAE: 1.15\n",
      "Epoch 1/30\n",
      "628/628 [==============================] - 4s 3ms/step - loss: 1.8451 - val_loss: 1.2897\n",
      "Epoch 2/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.9503 - val_loss: 1.1823\n",
      "Epoch 3/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.8758 - val_loss: 1.1323\n",
      "Epoch 4/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.8295 - val_loss: 1.0646\n",
      "Epoch 5/30\n",
      "628/628 [==============================] - 2s 2ms/step - loss: 0.7930 - val_loss: 1.0077\n",
      "Epoch 6/30\n",
      "628/628 [==============================] - 2s 2ms/step - loss: 0.7669 - val_loss: 0.9792\n",
      "Epoch 7/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7511 - val_loss: 0.9493\n",
      "Epoch 8/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7354 - val_loss: 0.9318\n",
      "Epoch 9/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 0.7277 - val_loss: 0.9600\n",
      "Epoch 10/30\n",
      "628/628 [==============================] - 2s 2ms/step - loss: 0.7213 - val_loss: 0.9159\n",
      "Epoch 11/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7165 - val_loss: 0.9062\n",
      "Epoch 12/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 0.7162 - val_loss: 0.9010\n",
      "Epoch 13/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 0.7146 - val_loss: 0.8950\n",
      "Epoch 14/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 0.7133 - val_loss: 0.8974\n",
      "Epoch 15/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7126 - val_loss: 0.8977\n",
      "Epoch 16/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7109 - val_loss: 0.8985\n",
      "Epoch 17/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7127 - val_loss: 0.8993\n",
      "Epoch 18/30\n",
      "628/628 [==============================] - 2s 2ms/step - loss: 0.7102 - val_loss: 0.8935\n",
      "Epoch 19/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7122 - val_loss: 0.8930\n",
      "Epoch 20/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7108 - val_loss: 0.8973\n",
      "Epoch 21/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7129 - val_loss: 0.9768\n",
      "Epoch 22/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7136 - val_loss: 0.9403\n",
      "Epoch 23/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7101 - val_loss: 0.9322\n",
      "Epoch 24/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7122 - val_loss: 0.9475\n",
      "73/73 [==============================] - 0s 1ms/step\n",
      "Symmetric Mean absolute percentage error: 15.69%. MASE: 1.24 MAE: 1.19\n",
      "Epoch 1/30\n",
      "628/628 [==============================] - 3s 2ms/step - loss: 1.3602 - val_loss: 1.2013\n",
      "Epoch 2/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.8299 - val_loss: 1.0552\n",
      "Epoch 3/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7712 - val_loss: 1.0300\n",
      "Epoch 4/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7512 - val_loss: 0.9797\n",
      "Epoch 5/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7363 - val_loss: 0.9568\n",
      "Epoch 6/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7283 - val_loss: 0.9470\n",
      "Epoch 7/30\n",
      "628/628 [==============================] - 2s 2ms/step - loss: 0.7216 - val_loss: 0.9319\n",
      "Epoch 8/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7174 - val_loss: 0.9263\n",
      "Epoch 9/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7162 - val_loss: 0.9755\n",
      "Epoch 10/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7154 - val_loss: 0.9295\n",
      "Epoch 11/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7136 - val_loss: 0.9324\n",
      "Epoch 12/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7138 - val_loss: 0.9201\n",
      "Epoch 13/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7125 - val_loss: 0.9176\n",
      "Epoch 14/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7120 - val_loss: 0.9129\n",
      "Epoch 15/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7110 - val_loss: 0.9126\n",
      "Epoch 16/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7091 - val_loss: 0.9107\n",
      "Epoch 17/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7100 - val_loss: 0.9187\n",
      "Epoch 18/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7085 - val_loss: 0.9097\n",
      "Epoch 19/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7093 - val_loss: 0.9086\n",
      "Epoch 20/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7075 - val_loss: 0.9035\n",
      "Epoch 21/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7086 - val_loss: 0.9912\n",
      "Epoch 22/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7089 - val_loss: 0.9527\n",
      "Epoch 23/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7064 - val_loss: 0.9440\n",
      "Epoch 24/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7080 - val_loss: 0.9408\n",
      "Epoch 25/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7062 - val_loss: 0.9236\n",
      "73/73 [==============================] - 0s 907us/step\n",
      "Symmetric Mean absolute percentage error: 14.70%. MASE: 1.15 MAE: 1.17\n",
      "Epoch 1/30\n",
      "628/628 [==============================] - 3s 2ms/step - loss: 1.3566 - val_loss: 1.1694\n",
      "Epoch 2/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.8183 - val_loss: 1.0167\n",
      "Epoch 3/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7525 - val_loss: 1.0202\n",
      "Epoch 4/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7317 - val_loss: 0.9510\n",
      "Epoch 5/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7199 - val_loss: 0.9324\n",
      "Epoch 6/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7183 - val_loss: 0.9427\n",
      "Epoch 7/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7171 - val_loss: 0.9223\n",
      "Epoch 8/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7151 - val_loss: 0.9332\n",
      "Epoch 9/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7148 - val_loss: 0.9435\n",
      "Epoch 10/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7150 - val_loss: 0.9299\n",
      "Epoch 11/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7131 - val_loss: 0.9278\n",
      "Epoch 12/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7142 - val_loss: 0.9160\n",
      "Epoch 13/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7140 - val_loss: 0.9116\n",
      "Epoch 14/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7125 - val_loss: 0.9142\n",
      "Epoch 15/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7119 - val_loss: 0.9177\n",
      "Epoch 16/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7098 - val_loss: 0.9233\n",
      "Epoch 17/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7112 - val_loss: 0.9222\n",
      "Epoch 18/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7086 - val_loss: 0.9210\n",
      "73/73 [==============================] - 0s 964us/step\n",
      "Symmetric Mean absolute percentage error: 14.85%. MASE: 1.13 MAE: 1.15\n",
      "Epoch 1/30\n",
      "628/628 [==============================] - 3s 2ms/step - loss: 1.1305 - val_loss: 1.2639\n",
      "Epoch 2/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.8855 - val_loss: 1.0417\n",
      "Epoch 3/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7744 - val_loss: 1.0717\n",
      "Epoch 4/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7401 - val_loss: 0.9244\n",
      "Epoch 5/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7204 - val_loss: 0.9012\n",
      "Epoch 6/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7185 - val_loss: 0.9148\n",
      "Epoch 7/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7187 - val_loss: 0.8965\n",
      "Epoch 8/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7170 - val_loss: 0.8949\n",
      "Epoch 9/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7159 - val_loss: 0.9218\n",
      "Epoch 10/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7167 - val_loss: 0.8991\n",
      "Epoch 11/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7138 - val_loss: 0.8985\n",
      "Epoch 12/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7155 - val_loss: 0.8981\n",
      "Epoch 13/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 0.7145 - val_loss: 0.8989\n",
      "73/73 [==============================] - 0s 991us/step\n",
      "Symmetric Mean absolute percentage error: 14.50%. MASE: 1.12 MAE: 1.14\n",
      "Epoch 1/30\n",
      "628/628 [==============================] - 3s 2ms/step - loss: 1.2427 - val_loss: 1.1201\n",
      "Epoch 2/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7877 - val_loss: 0.9912\n",
      "Epoch 3/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7413 - val_loss: 1.0248\n",
      "Epoch 4/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7351 - val_loss: 0.9364\n",
      "Epoch 5/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7253 - val_loss: 0.9318\n",
      "Epoch 6/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7245 - val_loss: 0.9507\n",
      "Epoch 7/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7243 - val_loss: 0.9225\n",
      "Epoch 8/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7214 - val_loss: 0.9258\n",
      "Epoch 9/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7204 - val_loss: 0.9348\n",
      "Epoch 10/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7195 - val_loss: 0.9456\n",
      "Epoch 11/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7169 - val_loss: 0.9156\n",
      "Epoch 12/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7178 - val_loss: 0.9155\n",
      "Epoch 13/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7169 - val_loss: 0.9102\n",
      "Epoch 14/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7146 - val_loss: 0.9095\n",
      "Epoch 15/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7143 - val_loss: 0.9142\n",
      "Epoch 16/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7115 - val_loss: 0.9210\n",
      "Epoch 17/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7133 - val_loss: 0.9224\n",
      "Epoch 18/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7105 - val_loss: 0.9208\n",
      "Epoch 19/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7117 - val_loss: 0.9180\n",
      "73/73 [==============================] - 0s 1ms/step\n",
      "Symmetric Mean absolute percentage error: 15.01%. MASE: 1.14 MAE: 1.16\n",
      "Epoch 1/30\n",
      "628/628 [==============================] - 3s 2ms/step - loss: 1.4977 - val_loss: 1.2117\n",
      "Epoch 2/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.8661 - val_loss: 1.0253\n",
      "Epoch 3/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7655 - val_loss: 1.0452\n",
      "Epoch 4/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7382 - val_loss: 0.9440\n",
      "Epoch 5/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7216 - val_loss: 0.9229\n",
      "Epoch 6/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7194 - val_loss: 0.9442\n",
      "Epoch 7/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7173 - val_loss: 0.9220\n",
      "Epoch 8/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7152 - val_loss: 0.9196\n",
      "Epoch 9/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7142 - val_loss: 0.9465\n",
      "Epoch 10/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7134 - val_loss: 0.9164\n",
      "Epoch 11/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7101 - val_loss: 0.9135\n",
      "Epoch 12/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7111 - val_loss: 0.9159\n",
      "Epoch 13/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7100 - val_loss: 0.9100\n",
      "Epoch 14/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7084 - val_loss: 0.9046\n",
      "Epoch 15/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7069 - val_loss: 0.9129\n",
      "Epoch 16/30\n",
      "628/628 [==============================] - 2s 3ms/step - loss: 0.7031 - val_loss: 0.9183\n",
      "Epoch 17/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7063 - val_loss: 0.9115\n",
      "Epoch 18/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7027 - val_loss: 0.9133\n",
      "Epoch 19/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7055 - val_loss: 0.9010\n",
      "Epoch 20/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7022 - val_loss: 0.9207\n",
      "Epoch 21/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7049 - val_loss: 1.0047\n",
      "Epoch 22/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7055 - val_loss: 0.9824\n",
      "Epoch 23/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7021 - val_loss: 0.9530\n",
      "Epoch 24/30\n",
      "628/628 [==============================] - 1s 2ms/step - loss: 0.7029 - val_loss: 0.9464\n",
      "73/73 [==============================] - 0s 1ms/step\n",
      "Symmetric Mean absolute percentage error: 15.30%. MASE: 1.21 MAE: 1.18\n"
     ]
    }
   ],
   "source": [
    "SMAPE_values = []\n",
    "MASE_values = []\n",
    "MAE_values = []\n",
    "\n",
    "for i in range(20):\n",
    "    K.clear_session()\n",
    "    tf.keras.backend.clear_session()\n",
    "    best_model, NN_sets = create_2cnn_model(best_window, best_n_layers, best_n_nodes, best_optimizer_name, best_lr, best_kernel_size)\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=5)\n",
    "    history = best_model.fit(\n",
    "        NN_sets['X_train'].reshape((-1, best_window)),\n",
    "        NN_sets['y_train'].reshape((-1, 1)),\n",
    "        epochs=30,\n",
    "        batch_size=16,\n",
    "        validation_data=(NN_sets['X_val'].reshape((-1, best_window)),\n",
    "                         NN_sets['y_val'].reshape((-1, 1))),\n",
    "        callbacks=[early_stop]\n",
    "    )\n",
    "    y_pred = best_model.predict(NN_sets['X_test'].reshape((-1, best_window)))\n",
    "    y_pred_df, SMAPE, MASE, MAE = NN_metricker(y_pred)\n",
    "    \n",
    "    # Append the metrics to the lists\n",
    "    SMAPE_values.append(SMAPE)\n",
    "    MASE_values.append(MASE)\n",
    "    MAE_values.append(MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "if not os.path.exists('final_thesis_CNN'):\n",
    "    os.makedirs('final_thesis_CNN')\n",
    "\n",
    "# Save the lists to pickle files in the specified directory\n",
    "with open('final_thesis_CNN/CNN_SMAPE_values.pkl', 'wb') as f:\n",
    "    pickle.dump(SMAPE_values, f)\n",
    "with open('final_thesis_CNN/CNN_MASE_values.pkl', 'wb') as f:\n",
    "    pickle.dump(MASE_values, f)\n",
    "with open('final_thesis_CNN/CNN_MAE_values.pkl', 'wb') as f:\n",
    "    pickle.dump(MAE_values, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prophet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
